# **Sentiment Analysis on Amazon Fine Food Reviews**
![Screenshot](screenshot.png)

## Overview
This project focuses on sentiment analysis using Amazon Fine Food reviews. The main objective is to build a robust model capable of accurately predicting the sentiment of reviews. Two models were developed: a **RandomForestClassifier** and a **PassiveAggressiveClassifier**. Throughout the project, special attention was given to the inconsistencies in the predictions and the importance of **model calibration** to enhance performance.

## Project Structure

The project is structured as follows:

1. **Data Collection**: Amazon Fine Food reviews dataset.
2. **Data Preprocessing**: Cleaning and preparing the data for model training.
3. **Model Development**: Implementing Random Forest and Passive-Aggressive Classifiers.
4. **Model Calibration**: Assessing and calibrating the models to improve prediction reliability.
5. **Evaluation**: Measuring the accuracy of the models on test and validation datasets.

## Key Insights
- **Model Calibration**: Initially, the models exhibited poor calibration. Through calibration techniques, the prediction reliability significantly improved.
- **Calibration Techniques**: Both ***PLATT*** scaling and ***SPLINE*** calibration were tested. PLATT scaling proved to be the most effective for both models.
- **Performance**: After calibration, both models showed substantial improvements in accuracy on validation data.

## Conclusion

In this project, I conducted a sentiment analysis on Amazon Fine Food Reviews. The data was first cleaned using the NLTK toolkit, followed by down-sampling to prevent class imbalance bias. Reviews were mapped onto a 0-2 scale, with 0 representing negative, 1 neutral, and 2 positive sentiments. I initially trained a **random forest classifier**, achieving **70%** accuracy and a log loss of **1.09**. After calibration using **Platt scaling** and **spline-calib** methods, the log loss improved to **0.68** and **0.69**, respectively. I then applied a **passive-aggressive classifier**, which outperformed the random forest with **80%** accuracy and a log loss of **0.53** post-calibration. The final model, a calibrated passive-aggressive classifier, achieved an impressive **100%** accuracy and a log loss of **0.23** on a test set of generic reviews generated by ChatGPT, demonstrating its effectiveness for sentiment prediction.
